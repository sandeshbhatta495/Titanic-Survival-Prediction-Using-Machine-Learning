# ğŸš¢ Titanic Survival Prediction using Machine Learning

A classic Machine Learning mini-project where I explore, clean, and model the Titanic dataset to predict which passengers survived the infamous shipwreck. This project is part of my AI/ML learning journey, and it marks my first complete end-to-end ML workflow â€” from raw data to Kaggle submission.

---

## ğŸ” Project Overview

- **Objective:** Predict survival on the Titanic using passenger data (classification problem).
- **Dataset:** [Kaggle Titanic Dataset](https://www.kaggle.com/c/titanic/data)
- **Model Used:** Logistic Regression
- **Accuracy Achieved:** ~73.67% (Training)

---

## ğŸ“ Project Structure


---

## ğŸ”§ Technologies Used

- Python
- Pandas, NumPy
- Matplotlib, Seaborn (EDA)
- Scikit-learn (ML model)
- Jupyter Notebook

---

## ğŸ§  What I Learned

- Data preprocessing using Pandas (`fillna`, `dropna`, `groupby`)
- Feature engineering and removal of irrelevant columns
- Label encoding for categorical features
- Applying Logistic Regression for binary classification
- Evaluating model performance
- Preparing submission files for Kaggle

---

## ğŸ“¤ Next Steps

- Explore advanced models: Decision Trees, Random Forests, XGBoost
- Perform hyperparameter tuning for improved accuracy
- Automate the workflow into a reproducible pipeline
- Build a frontend or simple Flask/Streamlit app for predictions

---

## ğŸ“ Kaggle Submission

Achieved ** 92.25 % accuracy** using Logistic Regression on the cleaned dataset. Submission was made successfully to the Kaggle Titanic competition.

---

## ğŸ“¢ Connect with Me

If you're also learning ML or working on similar beginner projects â€” let's connect!

ğŸ“Œ [LinkedIn](https://www.linkedin.com) | ğŸ“Œ [GitHub](https://github.com)

---

# ğŸš¢ Titanic Survival Prediction - Machine Learning Project

## ğŸ“Œ Overview

This project is part of my AI/ML learning journey (Day 1â€“8), where I built a machine learning model to predict the survival of passengers aboard the Titanic using supervised learning techniques. Itâ€™s an end-to-end implementation starting from raw data to a complete prediction pipeline.

## ğŸ¯ Objective

The goal is to predict whether a given passenger survived the Titanic disaster based on features like age, sex, class, fare, and more.

## ğŸ› ï¸ Technologies Used

* Python ğŸ
* Pandas ğŸ“Š
* NumPy ğŸ”¢
* Scikit-learn ğŸ¤–
* Matplotlib & Seaborn ğŸ“ˆ
* Jupyter Notebook ğŸ““

## ğŸ“‚ Dataset

Kaggle's Titanic Dataset:

* `train.csv` - training data
* `test.csv` - test data
* `gender_submission.csv` - sample submission

## ğŸ” Workflow

### 1. Data Loading & Exploration

* Loaded CSV files into DataFrames
* Performed exploratory data analysis (EDA)
* Visualized feature distributions

### 2. Data Preprocessing

* Handled missing values (`fillna`, `dropna`)
* Dropped irrelevant columns (Ticket, Cabin, Name)
* Feature Engineering (e.g., created new features)
* Label Encoding for categorical variables
* Exported cleaned dataset

### 3. Model Training

* Used Logistic Regression for binary classification
* Split training data using `train_test_split`
* Evaluated using accuracy (Train Accuracy: 70.2%)
* Final Kaggle Score: **73.67%**

### 4. Submission

* Made predictions on test set
* Exported results as `submission.csv`
* Submitted to Kaggle Titanic competition

## ğŸ“ˆ Output

* Final model: Logistic Regression
* Accuracy: \~73.67% (Kaggle LB Score)
* Submission file created successfully

## ğŸ§  What I Learned

* How to clean and preprocess data
* Importance of EDA and feature selection
* Model building and validation
* How to submit results on Kaggle
* Fundamentals of real-world ML pipelines

## ğŸ”® Whatâ€™s Next?

* Model evaluation with precision, recall, F1-score
* Cross-validation & hyperparameter tuning
* Explore Decision Trees & Random Forests
* Dive into ensemble learning techniques

## ğŸ¤ Connect

If you have suggestions or feedback, feel free to fork this repo, raise issues, or connect with me on [LinkedIn](https://www.linkedin.com/).

---

Built with ğŸ’» and curiosity by Sandesh ğŸš€
